"""
åœ°è´¨æ–‡æœ¬æ•°æ®å¤„ç†å™¨ - ä¸“é—¨é’ˆå¯¹åœ°è´¨LLMé¡¹ç›®ä¼˜åŒ–
åªå¤„ç†å¯¹æ–‡æœ¬åˆ†ææœ‰ä»·å€¼çš„æ–‡ä»¶ç±»å‹
"""
import os
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path

from rag_system import RAGSystem
from document_processor import DocumentProcessor

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GeologicalTextProcessor:
    """åœ°è´¨æ–‡æœ¬æ•°æ®å¤„ç†å™¨ - ä¸“æ³¨äºæ–‡æœ¬å†…å®¹æå–"""
    
    def __init__(self, enable_ocr: bool = True):
        """
        åˆå§‹åŒ–åœ°è´¨æ–‡æœ¬å¤„ç†å™¨
        
        Args:
            enable_ocr: æ˜¯å¦å¯ç”¨OCRï¼ˆç”¨äºæ‰«æPDFå’Œé‡è¦TIFï¼‰
        """
        # å®šä¹‰æ–‡ä»¶å¤„ç†ä¼˜å…ˆçº§
        self.high_priority_extensions = {
            # æ–‡æœ¬æ–‡æ¡£ - æœ€é«˜ä¼˜å…ˆçº§
            '.pdf', '.txt', '.docx', '.doc', '.md',
            # æ•°æ®æ–‡ä»¶ - é«˜ä¼˜å…ˆçº§  
            '.csv', '.xlsx', '.json'
        }
        
        self.medium_priority_extensions = {
            # å¯èƒ½åŒ…å«æ–‡æœ¬çš„å›¾åƒï¼ˆæ‰«ææ–‡æ¡£ï¼‰
            '.tif', '.tiff'  # åªå¤„ç†å¯èƒ½æ˜¯æ‰«ææ–‡æ¡£çš„TIF
        }
        
        self.skip_extensions = {
            # çº¯å›¾åƒæ–‡ä»¶ï¼ˆåœ°å±‚å›¾çº¿æ¡ï¼‰- è·³è¿‡
            '.jpg', '.jpeg', '.png', '.bmp', '.gif',
            # ç³»ç»Ÿæ–‡ä»¶ - è·³è¿‡
            '.ds_store', '.thumbs.db',
            # å‹ç¼©æ–‡ä»¶ - éœ€è¦ç‰¹æ®Šå¤„ç†
            '.zip', '.rar', '.7z',
            # ä¸“ä¸šè½¯ä»¶æ ¼å¼ - è·³è¿‡
            '.shp', '.shx', '.dbf', '.prj', '.cpg',
            '.db', '.tab', '.dat', '.ind', '.ovr', '.ghx', '.pprc'
        }
        
        self.enable_ocr = enable_ocr
        self.stats = {
            'processed_files': 0,
            'skipped_files': 0,
            'high_priority': 0,
            'medium_priority': 0,
            'file_types': {}
        }
    
    def analyze_data_directory(self, directory_path: str) -> Dict[str, Any]:
        """
        åˆ†ææ•°æ®ç›®å½•ï¼Œç»™å‡ºå¤„ç†å»ºè®®
        """
        path = Path(directory_path)
        if not path.exists():
            raise ValueError(f"ç›®å½•ä¸å­˜åœ¨: {directory_path}")
        
        analysis = {
            'high_priority': {},
            'medium_priority': {},
            'low_priority': {},
            'skip': {},
            'total_files': 0,
            'recommendations': []
        }
        
        # ç»Ÿè®¡æ–‡ä»¶
        for file_path in path.rglob('*'):
            if file_path.is_file():
                ext = file_path.suffix.lower()
                analysis['total_files'] += 1
                
                if ext in self.high_priority_extensions:
                    analysis['high_priority'][ext] = analysis['high_priority'].get(ext, 0) + 1
                elif ext in self.medium_priority_extensions:
                    analysis['medium_priority'][ext] = analysis['medium_priority'].get(ext, 0) + 1
                elif ext in self.skip_extensions:
                    analysis['skip'][ext] = analysis['skip'].get(ext, 0) + 1
                else:
                    analysis['low_priority'][ext] = analysis['low_priority'].get(ext, 0) + 1
        
        # ç”Ÿæˆå»ºè®®
        analysis['recommendations'] = self._generate_recommendations(analysis)
        
        return analysis
    
    def _generate_recommendations(self, analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå¤„ç†å»ºè®®"""
        recommendations = []
        
        # é«˜ä¼˜å…ˆçº§æ–‡ä»¶å»ºè®®
        if analysis['high_priority']:
            total_high = sum(analysis['high_priority'].values())
            recommendations.append(f"âœ… å»ºè®®å¤„ç† {total_high} ä¸ªé«˜ä¼˜å…ˆçº§æ–‡ä»¶ï¼ˆPDFã€æ–‡æœ¬ã€æ•°æ®æ–‡ä»¶ï¼‰")
            
            if '.pdf' in analysis['high_priority']:
                pdf_count = analysis['high_priority']['.pdf']
                recommendations.append(f"ğŸ“„ {pdf_count} ä¸ªPDFæ–‡ä»¶å»ºè®®å¯ç”¨OCRï¼ˆå¾ˆå¤šæ˜¯æ‰«ææ–‡æ¡£ï¼‰")
        
        # ä¸­ç­‰ä¼˜å…ˆçº§å»ºè®®
        if analysis['medium_priority']:
            total_medium = sum(analysis['medium_priority'].values())
            if '.tif' in analysis['medium_priority']:
                tif_count = analysis['medium_priority']['.tif']
                recommendations.append(f"âš ï¸  {tif_count} ä¸ªTIFæ–‡ä»¶ï¼šå»ºè®®å…ˆé‡‡æ ·æ£€æŸ¥æ˜¯å¦ä¸ºæ‰«ææ–‡æ¡£")
                recommendations.append(f"   å¦‚æœæ˜¯åœ°å±‚å›¾çº¿æ¡ï¼Œå»ºè®®è·³è¿‡ï¼›å¦‚æœæ˜¯æ‰«ææŠ¥å‘Šï¼Œå»ºè®®OCRå¤„ç†")
        
        # è·³è¿‡æ–‡ä»¶å»ºè®®
        if analysis['skip']:
            total_skip = sum(analysis['skip'].values())
            recommendations.append(f"â­ï¸  å»ºè®®è·³è¿‡ {total_skip} ä¸ªæ–‡ä»¶ï¼ˆçº¯å›¾åƒã€ç³»ç»Ÿæ–‡ä»¶ç­‰ï¼‰")
            
            if '.jpg' in analysis['skip']:
                jpg_count = analysis['skip']['.jpg']
                recommendations.append(f"ğŸ“¸ {jpg_count} ä¸ªJPGæ–‡ä»¶ä¸»è¦æ˜¯åœ°å±‚å›¾çº¿æ¡ï¼Œå¯¹æ–‡æœ¬åˆ†æä»·å€¼æœ‰é™")
        
        # å­˜å‚¨ç©ºé—´å»ºè®®
        total_process = sum(analysis['high_priority'].values()) + sum(analysis['medium_priority'].values())
        total_skip = sum(analysis['skip'].values())
        if total_skip > total_process:
            recommendations.append(f"ğŸ’¾ å¯èŠ‚çœ {total_skip}/{analysis['total_files']} æ–‡ä»¶çš„å¤„ç†æ—¶é—´")
        
        return recommendations
    
    def create_optimized_rag_system(self, 
                                  model_name: str = "qwen2.5:7b",
                                  process_medium_priority: bool = False) -> RAGSystem:
        """
        åˆ›å»ºä¼˜åŒ–çš„RAGç³»ç»Ÿï¼Œåªå¤„ç†æœ‰ä»·å€¼çš„æ–‡ä»¶
        
        Args:
            model_name: æ¨¡å‹åç§°
            process_medium_priority: æ˜¯å¦å¤„ç†ä¸­ç­‰ä¼˜å…ˆçº§æ–‡ä»¶ï¼ˆTIFï¼‰
        """
        
        # ç¡®å®šè¦æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
        supported_extensions = self.high_priority_extensions.copy()
        
        if process_medium_priority:
            supported_extensions.update(self.medium_priority_extensions)
            logger.info("å¯ç”¨ä¸­ç­‰ä¼˜å…ˆçº§æ–‡ä»¶å¤„ç†ï¼ˆåŒ…æ‹¬TIFæ–‡ä»¶OCRï¼‰")
        
        # åˆ›å»ºè‡ªå®šä¹‰æ–‡æ¡£å¤„ç†å™¨
        class OptimizedDocumentProcessor(DocumentProcessor):
            def __init__(self, supported_exts, enable_ocr):
                super().__init__(enable_image_processing=True, enable_ocr=enable_ocr)
                # é‡å†™æ”¯æŒçš„æ‰©å±•å
                self.supported_extensions = supported_exts
                logger.info(f"ä¼˜åŒ–å¤„ç†å™¨ï¼šæ”¯æŒ {len(supported_exts)} ç§æ–‡ä»¶ç±»å‹")
                logger.info(f"æ”¯æŒçš„æ ¼å¼: {sorted(supported_exts)}")
        
        # åˆ›å»ºRAGç³»ç»Ÿ
        rag = RAGSystem(
            model_name=model_name,
            enable_image_processing=process_medium_priority,  # åªæœ‰å¤„ç†TIFæ—¶æ‰å¯ç”¨
            enable_ocr=self.enable_ocr,
            max_images=500 if process_medium_priority else 0,  # é™åˆ¶TIFå¤„ç†æ•°é‡
            chunk_size=512,
            similarity_top_k=5,
            persist_dir="./geological_text_db"
        )
        
        # æ›¿æ¢æ–‡æ¡£å¤„ç†å™¨
        rag.doc_processor = OptimizedDocumentProcessor(supported_extensions, self.enable_ocr)
        
        return rag
    
    def process_geological_data(self, 
                              directory_path: str,
                              process_medium_priority: bool = False,
                              model_name: str = "qwen2.5:7b") -> RAGSystem:
        """
        å¤„ç†åœ°è´¨æ•°æ®çš„ä¸»å‡½æ•°
        
        Args:
            directory_path: æ•°æ®ç›®å½•
            process_medium_priority: æ˜¯å¦å¤„ç†TIFæ–‡ä»¶
            model_name: æ¨¡å‹åç§°
            
        Returns:
            é…ç½®å¥½çš„RAGç³»ç»Ÿ
        """
        
        print("ğŸŒ åœ°è´¨æ–‡æœ¬æ•°æ®å¤„ç†ç³»ç»Ÿ")
        print("="*40)
        
        # 1. åˆ†ææ•°æ®ç›®å½•
        print("ğŸ” åˆ†ææ•°æ®ç›®å½•...")
        analysis = self.analyze_data_directory(directory_path)
        
        print(f"\nğŸ“Š æ–‡ä»¶åˆ†æç»“æœ:")
        print(f"æ€»æ–‡ä»¶æ•°: {analysis['total_files']}")
        print(f"é«˜ä¼˜å…ˆçº§: {sum(analysis['high_priority'].values())} ä¸ª")
        print(f"ä¸­ç­‰ä¼˜å…ˆçº§: {sum(analysis['medium_priority'].values())} ä¸ª") 
        print(f"å»ºè®®è·³è¿‡: {sum(analysis['skip'].values())} ä¸ª")
        
        print(f"\nğŸ“‹ å¤„ç†å»ºè®®:")
        for rec in analysis['recommendations']:
            print(f"  {rec}")
        
        # 2. ç”¨æˆ·ç¡®è®¤
        if not process_medium_priority and analysis['medium_priority']:
            tif_count = analysis['medium_priority'].get('.tif', 0)
            if tif_count > 0:
                print(f"\nâš ï¸  å‘ç° {tif_count} ä¸ªTIFæ–‡ä»¶")
                print("è¿™äº›å¯èƒ½æ˜¯ï¼š1) æ‰«æçš„åœ°è´¨æŠ¥å‘Šï¼ˆæœ‰ä»·å€¼ï¼‰ 2) åœ°å±‚å›¾çº¿æ¡ï¼ˆä»·å€¼æœ‰é™ï¼‰")
                
        # 3. åˆ›å»ºä¼˜åŒ–çš„RAGç³»ç»Ÿ
        print(f"\nğŸš€ åˆ›å»ºä¼˜åŒ–çš„RAGç³»ç»Ÿ...")
        rag = self.create_optimized_rag_system(model_name, process_medium_priority)
        
        # 4. å¤„ç†æ•°æ®
        print(f"ğŸ“š å¼€å§‹å¤„ç†æ•°æ®...")
        rag.add_documents(directory_path)
        
        # 5. æ˜¾ç¤ºç»“æœ
        stats = rag.get_stats()
        print(f"\nâœ… å¤„ç†å®Œæˆ!")
        print(f"æ–‡æ¡£æ€»æ•°: {stats.get('document_count', 0)}")
        
        return rag


def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    import argparse
    
    parser = argparse.ArgumentParser(description="åœ°è´¨æ–‡æœ¬æ•°æ®å¤„ç†")
    parser.add_argument("--data-path", required=True, help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--include-tif", action="store_true", help="æ˜¯å¦å¤„ç†TIFæ–‡ä»¶")
    parser.add_argument("--no-ocr", action="store_true", help="ç¦ç”¨OCR")
    parser.add_argument("--analyze-only", action="store_true", help="ä»…åˆ†æï¼Œä¸å¤„ç†")
    
    args = parser.parse_args()
    
    processor = GeologicalTextProcessor(enable_ocr=not args.no_ocr)
    
    if args.analyze_only:
        # ä»…åˆ†ææ¨¡å¼
        analysis = processor.analyze_data_directory(args.data_path)
        print("ğŸ“Š æ•°æ®åˆ†æç»“æœ:")
        for rec in analysis['recommendations']:
            print(f"  {rec}")
    else:
        # å¤„ç†æ•°æ®
        rag = processor.process_geological_data(
            args.data_path,
            process_medium_priority=args.include_tif
        )
        
        # ç®€å•æµ‹è¯•
        result = rag.query("è¿™äº›æ•°æ®ä¸­åŒ…å«å“ªäº›ç±»å‹çš„åœ°è´¨ä¿¡æ¯ï¼Ÿ")
        print(f"\nğŸ§ª æµ‹è¯•æŸ¥è¯¢ç»“æœ: {result['answer'][:200]}...")


if __name__ == "__main__":
    # i dont want to use main. i want to define all parameters in the code. and use them to create a rag system.
    rag = GeologicalTextProcessor(enable_ocr=True)
    rag.process_geological_data(
        directory_path="/Users/yjli/QUTIT/semester4/ifn712/datacollect/cr088747-2014",
        process_medium_priority=True,
        model_name="qwen2.5:7b"
    )
